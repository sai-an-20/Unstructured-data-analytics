{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8636768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim import models\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import chisquare\n",
    "from collections import Counter\n",
    "from scipy.optimize import minimize_scalar\n",
    "import operator\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.manifold import MDS\n",
    "from gensim import corpora, models\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba9314",
   "metadata": {},
   "source": [
    "## Netflix Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf37699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data into a Pandas DataFrame\n",
    "data = pd.read_csv('Netflix_All_Input_vF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90be1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0        int64\n",
       "post_link        object\n",
       "comment_count     int64\n",
       "likes_count       int64\n",
       "caption          object\n",
       "is_video           bool\n",
       "image_link       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e02f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess your text data (tokenization, remove stopwords, etc.)\n",
    "\n",
    "data['caption'] = data['caption'].apply(lambda x: str(x) if not isinstance(x, str) else x)\n",
    "\n",
    "# Join all 'caption' values into a single string\n",
    "all_reviews_text = ' '.join(data['caption'].tolist())\n",
    "\n",
    "# Perform text cleaning and tokenization\n",
    "all_reviews_text = re.sub(r'[^\\w\\s]', '', all_reviews_text)\n",
    "all_reviews_text = all_reviews_text.lower()\n",
    "words = word_tokenize(all_reviews_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f51a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfaf9c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c01fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = FreqDist(words)\n",
    "freq_dist = sorted(freq_dist.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce27de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vectorize the text data using TF-IDF\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "# tfidf_matrix = tfidf_vectorizer.fit_transform(data['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5130ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary([words])\n",
    "corpus = [dictionary.doc2bow(words)]\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=3, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b106421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.009*\"come\" + 0.005*\"season\" + 0.005*\"tudum\" + 0.005*\"one\" + 0.005*\"netflix\" + 0.005*\"new\" + 0.004*\"live\" + 0.004*\"look\" + 0.003*\"heart\" + 0.003*\"cant\"\n",
      "Topic 1: 0.010*\"come\" + 0.008*\"netflix\" + 0.006*\"new\" + 0.006*\"one\" + 0.006*\"season\" + 0.006*\"love\" + 0.006*\"onepiecenetflix\" + 0.005*\"tudum\" + 0.005*\"look\" + 0.005*\"live\"\n",
      "Topic 2: 0.009*\"come\" + 0.007*\"new\" + 0.007*\"netflix\" + 0.006*\"season\" + 0.005*\"live\" + 0.005*\"one\" + 0.005*\"onepiecenetflix\" + 0.005*\"tudum\" + 0.004*\"love\" + 0.004*\"heart\"\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {topic_id}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874e6917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.9620851), (2, 0.037680224)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus:\n",
    "    print(lda_model.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8164167",
   "metadata": {},
   "source": [
    "## Disney Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a863ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.058*\"disneyplu\" + 0.039*\"stream\" + 0.011*\"studio\" + 0.010*\"origin\" + 0.009*\"new\" + 0.008*\"seri\" + 0.008*\"season\" + 0.007*\"check\" + 0.007*\"premier\" + 0.007*\"themandalorian\"\n",
      "Topic 1: 0.058*\"disneyplu\" + 0.053*\"stream\" + 0.012*\"origin\" + 0.010*\"studio\" + 0.010*\"marvel\" + 0.008*\"seri\" + 0.008*\"new\" + 0.008*\"season\" + 0.007*\"2\" + 0.007*\"come\"\n",
      "[(0, 0.08641486), (1, 0.9135852)]\n"
     ]
    }
   ],
   "source": [
    "# Load your data into a Pandas DataFrame\n",
    "data = pd.read_csv('DisneyPlus_All_Input_vF.csv')\n",
    "\n",
    "# Preprocess your text data (tokenization, remove stopwords, etc.)\n",
    "\n",
    "data['caption'] = data['caption'].apply(lambda x: str(x) if not isinstance(x, str) else x)\n",
    "\n",
    "# Join all 'caption' values into a single string\n",
    "all_reviews_text = ' '.join(data['caption'].tolist())\n",
    "\n",
    "# Perform text cleaning and tokenization\n",
    "all_reviews_text = re.sub(r'[^\\w\\s]', '', all_reviews_text)\n",
    "all_reviews_text = all_reviews_text.lower()\n",
    "words = word_tokenize(all_reviews_text)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "freq_dist = FreqDist(words)\n",
    "freq_dist = sorted(freq_dist.items(), key=operator.itemgetter(1), reverse = True)\n",
    "\n",
    "dictionary = corpora.Dictionary([words])\n",
    "corpus = [dictionary.doc2bow(words)]\n",
    "\n",
    "lda_model = models.LdaModel(corpus, num_topics=2, id2word=dictionary)\n",
    "\n",
    "for topic_id, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {topic_id}: {topic}\")\n",
    "\n",
    "for doc in corpus:\n",
    "    print(lda_model.get_document_topics(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf454a33",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32684\\2138769750.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtopic_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtopic_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' + '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Plot the bar chart for each topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32684\\2138769750.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtopic_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtopic_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' + '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Plot the bar chart for each topic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the weights (probabilities) and words for each topic\n",
    "topic_words = []\n",
    "for topic in topic:\n",
    "    topic_words.append([word.split('*')[1].strip('\"') for word in topic.split(' + ')])\n",
    "\n",
    "# Plot the bar chart for each topic\n",
    "num_topics = len(topics)\n",
    "num_words = len(topic_words[0])  # Assuming all topics have the same number of words\n",
    "word_weights = []\n",
    "\n",
    "for i in range(num_words):\n",
    "    word_weights.append([float(topic.split('*')[i].split('\"')[0]) for topic in topics])\n",
    "\n",
    "# Set the x-axis labels (words)\n",
    "words = [word for word in word_weights[0]]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_topics):\n",
    "    plt.barh(words, word_weights[i], label=f\"Topic {i}\")\n",
    "\n",
    "plt.xlabel(\"Word Weight\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.title(\"Word Distribution in LDA Topics\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089bc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067f802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
